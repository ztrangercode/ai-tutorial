{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9b321c",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4af9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac0d4e",
   "metadata": {},
   "source": [
    "## 2. Define Data Transformations\n",
    "\n",
    "Before loading the data, we define transformations to:\n",
    "- Convert images to PyTorch tensors\n",
    "- Normalize pixel values to a standard range\n",
    "\n",
    "MNIST images have pixel values from 0-255. We normalize them to have:\n",
    "- Mean = 0.1307\n",
    "- Standard deviation = 0.3081\n",
    "\n",
    "These are the mean and std of the MNIST dataset, calculated across all training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf540e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL Image to tensor and scale to [0, 1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
    "])\n",
    "\n",
    "print(\"Transformations defined:\")\n",
    "print(\"1. Convert to tensor (scales pixel values to [0, 1])\")\n",
    "print(\"2. Normalize with mean=0.1307, std=0.3081\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee4d76",
   "metadata": {},
   "source": [
    "## 3. Load the MNIST Dataset\n",
    "\n",
    "PyTorch's `torchvision.datasets` makes it easy to download and load MNIST.\n",
    "The dataset will be automatically downloaded to the `../data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52aae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='../data',           # Where to save/load the data\n",
    "    train=True,               # Load training set\n",
    "    download=True,            # Download if not already present\n",
    "    transform=transform       # Apply transformations\n",
    ")\n",
    "\n",
    "# Load test data\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='../data',\n",
    "    train=False,              # Load test set\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a54702",
   "metadata": {},
   "source": [
    "## 4. Explore the Dataset Structure\n",
    "\n",
    "Let's look at a single sample to understand the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first sample\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Image type: {type(image)}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Label type: {type(label)}\")\n",
    "\n",
    "print(f\"\\nImage details:\")\n",
    "print(f\"  - Channels: {image.shape[0]} (grayscale)\")\n",
    "print(f\"  - Height: {image.shape[1]} pixels\")\n",
    "print(f\"  - Width: {image.shape[2]} pixels\")\n",
    "print(f\"  - Min value: {image.min():.3f}\")\n",
    "print(f\"  - Max value: {image.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9269a830",
   "metadata": {},
   "source": [
    "## 5. Visualize Sample Images\n",
    "\n",
    "Let's visualize some samples to see what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display an image\n",
    "def show_image(image, label):\n",
    "    # Remove channel dimension and convert to numpy\n",
    "    image = image.squeeze().numpy()\n",
    "    \n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Display the first image\n",
    "image, label = train_dataset[0]\n",
    "plt.figure(figsize=(3, 3))\n",
    "show_image(image, label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3175df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid of sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "fig.suptitle('Sample MNIST Images', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    \n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f\"Label: {label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ae677f",
   "metadata": {},
   "source": [
    "## 6. Visualize One Example of Each Digit\n",
    "\n",
    "Let's find and display one example of each digit (0-9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find one example of each digit\n",
    "digit_examples = {}\n",
    "\n",
    "for image, label in train_dataset:\n",
    "    if label not in digit_examples:\n",
    "        digit_examples[label] = image\n",
    "    \n",
    "    # Stop when we have all 10 digits\n",
    "    if len(digit_examples) == 10:\n",
    "        break\n",
    "\n",
    "# Display them\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "fig.suptitle('One Example of Each Digit (0-9)', fontsize=16)\n",
    "\n",
    "for digit in range(10):\n",
    "    ax = axes[digit // 5, digit % 5]\n",
    "    image = digit_examples[digit].squeeze().numpy()\n",
    "    \n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.set_title(f\"Digit: {digit}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b59dbf1",
   "metadata": {},
   "source": [
    "## 7. Analyze Class Distribution\n",
    "\n",
    "Let's check if the dataset is balanced (roughly equal number of each digit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63649832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each digit in training set\n",
    "from collections import Counter\n",
    "\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "label_counts = Counter(train_labels)\n",
    "\n",
    "# Print counts\n",
    "print(\"Training set class distribution:\")\n",
    "for digit in range(10):\n",
    "    count = label_counts[digit]\n",
    "    percentage = (count / len(train_dataset)) * 100\n",
    "    print(f\"  Digit {digit}: {count:5d} samples ({percentage:.1f}%)\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(10), [label_counts[i] for i in range(10)])\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Number of Samples')\n",
    "plt.title('MNIST Training Set - Class Distribution')\n",
    "plt.xticks(range(10))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ The dataset is well-balanced!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e17eca0",
   "metadata": {},
   "source": [
    "## 8. Create Data Loaders\n",
    "\n",
    "DataLoaders handle batching, shuffling, and parallel data loading.\n",
    "This is crucial for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,           # Shuffle training data\n",
    "    num_workers=0           # Number of subprocesses for data loading (0 = main process)\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,          # Don't shuffle test data\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Number of training batches: {len(train_loader)}\")\n",
    "print(f\"Number of test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b0506",
   "metadata": {},
   "source": [
    "## 9. Examine a Batch\n",
    "\n",
    "Let's look at what a batch of data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d52eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch from the train loader\n",
    "batch_images, batch_labels = next(iter(train_loader))\n",
    "\n",
    "print(f\"Batch images shape: {batch_images.shape}\")\n",
    "print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "print(f\"\\nBatch breakdown:\")\n",
    "print(f\"  - Batch size: {batch_images.shape[0]} images\")\n",
    "print(f\"  - Channels: {batch_images.shape[1]}\")\n",
    "print(f\"  - Height: {batch_images.shape[2]}\")\n",
    "print(f\"  - Width: {batch_images.shape[3]}\")\n",
    "print(f\"\\nFirst 10 labels in batch: {batch_labels[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch\n",
    "fig, axes = plt.subplots(4, 8, figsize=(15, 8))\n",
    "fig.suptitle(f'One Batch of {batch_size} Images', fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(batch_images):\n",
    "        image = batch_images[i].squeeze().numpy()\n",
    "        label = batch_labels[i].item()\n",
    "        \n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.set_title(f\"{label}\")\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ea411",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "Congratulations! You've completed Exercise 2. You now know:\n",
    "\n",
    "✅ How to load the MNIST dataset using torchvision\n",
    "\n",
    "✅ How to apply transformations (conversion to tensor and normalization)\n",
    "\n",
    "✅ The structure of the MNIST dataset (60,000 training + 10,000 test images)\n",
    "\n",
    "✅ How to visualize images and analyze the dataset\n",
    "\n",
    "✅ How to create DataLoaders for efficient batching\n",
    "\n",
    "✅ What a batch of data looks like\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- MNIST images are 28×28 grayscale pixels\n",
    "- The dataset is well-balanced across all 10 digits\n",
    "- Normalization helps neural networks train faster and more effectively\n",
    "- DataLoaders handle batching and shuffling automatically\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In Exercise 3, we'll build a neural network to classify these digits!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
